{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17928368491020697642\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "from tensorflow.python.client import device_lib\n",
    "import pickle\n",
    "print(device_lib.list_local_devices())\n",
    "import numpy as np\n",
    "#from School.STAT946.Project impimport GAN\n",
    "import keras\n",
    "import GAN\n",
    "from Losses import *\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = (500/12000)\n",
    "set_session(tf.Session(config=config))\n",
    "'''\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "# Assume that you have 12GB of GPU memory and want to allocate 500MB:\n",
    "config.gpu_options.per_process_gpu_memory_fraction=(500/12000)\n",
    "sess = tf.Session(config=config)'''\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_n(epochs=5000,batch_size=128):\n",
    "    #from tqdm import tqdm\n",
    "    \n",
    "    for tk in range(epochs):\n",
    "        if(tk==0):\n",
    "            print(\"Entered the loop\")\n",
    "        # Make generative images\n",
    "        real_image_batch = X[np.random.randint(0,X.shape[0],size=int(batch_size/2)),:,:,:]\n",
    "        fake_image_inp = X[np.random.randint(0,X.shape[0],size=int(batch_size/2)),:,:,:]\n",
    "        fake_image_batch = np.add(fake_image_inp,G.predict(fake_image_inp))\n",
    "\n",
    "        # Train discriminator on generated images\n",
    "        X_batch = np.concatenate((real_image_batch, fake_image_batch))\n",
    "        y1 = np.zeros([batch_size,1])\n",
    "        y1[0:int(batch_size/2),] = 1\n",
    "        \n",
    "        make_trainable(D,True)\n",
    "        D.train_on_batch(X_batch,y1)\n",
    "        #d_loss  = D.train_on_batch(X_batch,y1)\n",
    "        #losses[\"d\"][e]=d_loss\n",
    "\n",
    "        #train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        sample_int=np.random.randint(0,X.shape[0],size=int(batch_size))\n",
    "        fake_image_inp = X[sample_int,:,:,:]\n",
    "        y_discrim = np.ones([batch_size,1])\n",
    "        y_class=y[sample_int]\n",
    "        y_hinge=np.zeros([batch_size,28,28,1])\n",
    "        \n",
    "        make_trainable(D,False)\n",
    "        scalarloss=GAN.train_on_batch(fake_image_inp, [y_discrim,y_class,y_hinge])\n",
    "        #g_loss = GAN.train_on_batch(noise_tr, y2 )\n",
    "        if(tk%500==0):\n",
    "            print(\"Epoch number:\",tk,\"; Loss\",scalarloss)\n",
    "         #losses[\"g\"][e]=g_loss\n",
    "    #GAN.save('GAN_CPristine100')\n",
    "    #G.save('G_CPristine100')\n",
    "    #D.save('D_CPristine100')\n",
    "    #f.save('f_CPristine100')\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew\n",
      "I'm here 111\n",
      "Tensor(\"model_1_target:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 28, 28, 1)     85757       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 28, 28, 1)     0           input_3[0][0]                    \n",
      "                                                                   model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 1)             10717       add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 10)            893258      add_5[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 989,732\n",
      "Trainable params: 96,474\n",
      "Non-trainable params: 893,258\n",
      "____________________________________________________________________________________________________\n",
      "=||==||==||==||==||==||==||=\n",
      "=||==||==||==||==||==||==||=\n",
      "Model F\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 21, 21, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                184330    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 893,258\n",
      "Trainable params: 0\n",
      "Non-trainable params: 893,258\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN, G, D, f= GAN.Define_GAN([28,28,1], 100, 10000,'B')\n",
    "print(\"=||=\"*7)\n",
    "print(\"=||=\"*7)\n",
    "#f.summary()\n",
    "(X,y),(_,_)=mnist.load_data()\n",
    "X= np.divide(X,255)\n",
    "X=X.reshape(X.shape[0],28,28,1)\n",
    "y=to_categorical(y, num_classes=10)\n",
    "make_trainable(f,False)\n",
    "print('Model F\\n')\n",
    "f.summary()\n",
    "#make_trainable(f2,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered the loop\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64a7984d7101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_for_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WhiteBox/B_Wbox_Ganwt3k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WhiteBox/B_Wbox_Gwt3k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WhiteBox/B_Wbox_Dwt3k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WhiteBox/B_Wbox_fwt3k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-78f804b9537f>\u001b[0m in \u001b[0;36mtrain_for_n\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entered the loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Make generative images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mreal_image_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mfake_image_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfake_image_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "train_for_n(epochs=2000,batch_size=128)\n",
    "GAN.save_weights('WhiteBox/B_Wbox_Ganwt3k')\n",
    "G.save_weights('WhiteBox/B_Wbox_Gwt3k')\n",
    "D.save_weights('WhiteBox/B_Wbox_Dwt3k')\n",
    "f.save_weights('WhiteBox/B_Wbox_fwt3k')\n",
    "print('Done')\n",
    "#GAN.save('GAN_BPristine15000')\n",
    "#G.save('G_BPristine15000')\n",
    "#D.save('D_BPristine15000')\n",
    "#f.save('f_BPristine15000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the compile function for C. To be called \"After freezing the weights\"\n",
    "#sgd= SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#f2.compile(loss=fn,optimizer=sgd,metrics=['accuracy'])\n",
    "#f.summary()\n",
    "#make_trainable(f2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GAN.load_weights('WhiteBox/B_Wbox_Ganwt2k')\\nG.load_weights('WhiteBox/B_Wbox_Gwt2k')\\nD.load_weights('WhiteBox/B_Wbox_Dwt2k')\\nf.load_weights('WhiteBox/B_Wbox_fwt2k')\\nmake_trainable(f, False)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GAN, G, D, f= GAN.Define_GAN([28,28,1], 1, 10000,'B')\n",
    "'''GAN.load_weights('WhiteBox/B_Wbox_Ganwt2k')\n",
    "G.load_weights('WhiteBox/B_Wbox_Gwt2k')\n",
    "D.load_weights('WhiteBox/B_Wbox_Dwt2k')\n",
    "f.load_weights('WhiteBox/B_Wbox_fwt2k')\n",
    "make_trainable(f, False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
